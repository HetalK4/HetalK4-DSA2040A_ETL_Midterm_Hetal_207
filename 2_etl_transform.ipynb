{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f6a62e",
   "metadata": {},
   "source": [
    "## raw_data.csv\n",
    "\n",
    "Apply at least 4 meaningful transformations:\n",
    "\n",
    "- Cleaning: Handle missing values, remove duplicates\n",
    "\n",
    "- Enrichment: Add 'total_price' = 'quantity' * 'unit_price'\n",
    "\n",
    "- Structural: Convert dates, change data types\n",
    "\n",
    "- Filtering: Drop irrelevant columns or rows\n",
    "\n",
    "- Categorization: Create age bins, customer tiers\n",
    "\n",
    "Save the transformed files to 'transformed/' folder\n",
    "\n",
    "NB: \n",
    "\n",
    "- Show before and after for each transformation.\n",
    "\n",
    "- Explain what and why you are transforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadc19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Loading 'raw_data.csv'\n",
    "raw_data = pd.read_csv(\"raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5690bc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values before transformation are: \n",
      " order_id          0\n",
      "customer_name     1\n",
      "product           0\n",
      "quantity         26\n",
      "unit_price       35\n",
      "order_date        1\n",
      "region           25\n",
      "dtype: int64 \n",
      "\n",
      "The number of duplicate rows before transformation include: \n",
      " 1 \n",
      "\n",
      "The number of missing values after transformation are: \n",
      " order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64 \n",
      "\n",
      "The number of duplicate rows after transformation include: \n",
      " 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cleaning 'raw_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "missing_values_raw = raw_data.isnull().sum()\n",
    "print(f\"The number of missing values before transformation are: \\n {missing_values_raw} \\n\")\n",
    "\n",
    "duplicates_raw = raw_data.duplicated().sum()\n",
    "print(f\"The number of duplicate rows before transformation include: \\n {duplicates_raw} \\n\")\n",
    "\n",
    "# Transformation:\n",
    "# Fill missing values\n",
    "for col in raw_data.columns:\n",
    "    if raw_data[col].dtype in ['int64', 'float64']:\n",
    "        raw_data[col] = raw_data[col].fillna(raw_data[col].mean())\n",
    "    else:\n",
    "        raw_data[col] = raw_data[col].fillna(raw_data[col].mode()[0])\n",
    "# Remove duplicates\n",
    "raw_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# After transformation\n",
    "missing_values_after = raw_data.isnull().sum()\n",
    "print(f\"The number of missing values after transformation are: \\n {missing_values_after} \\n\")\n",
    "\n",
    "duplicates_after = raw_data.duplicated().sum()\n",
    "print(f\"The number of duplicate rows after transformation include: \\n {duplicates_after} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade833c",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "    Handling missing values is essential to avoid errors during analysis. Therefore, filled numerical columns with its corresponding mean and descriptive columns with its corresponding mode.\n",
    "\n",
    "    To ensure data integrity, the one duplicate row is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34998553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 observations in the dataset are: \n",
      "    order_id customer_name product  quantity  unit_price  order_date region\n",
      "0         1         Diana  Tablet  1.959459       500.0  2024-01-20  South\n",
      "1         2           Eve  Laptop  1.959459       500.0  2024-04-29  North\n",
      "2         3       Charlie  Laptop  2.000000       250.0  2024-01-08  South\n",
      "3         4           Eve  Laptop  2.000000       750.0  2024-01-07   West\n",
      "4         5           Eve  Tablet  3.000000       500.0  2024-03-07  South \n",
      "\n",
      "The first 5 observations in the dataset after adding a new column are: \n",
      "    order_id customer_name product  quantity  unit_price  order_date region  \\\n",
      "0         1         Diana  Tablet  1.959459       500.0  2024-01-20  South   \n",
      "1         2           Eve  Laptop  1.959459       500.0  2024-04-29  North   \n",
      "2         3       Charlie  Laptop  2.000000       250.0  2024-01-08  South   \n",
      "3         4           Eve  Laptop  2.000000       750.0  2024-01-07   West   \n",
      "4         5           Eve  Tablet  3.000000       500.0  2024-03-07  South   \n",
      "\n",
      "   total_price  \n",
      "0    979.72973  \n",
      "1    979.72973  \n",
      "2    500.00000  \n",
      "3   1500.00000  \n",
      "4   1500.00000   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enriching 'raw_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "# Displaying the first 5 observations along with their columns in the dataset\n",
    "print(f\"The first 5 observations in the dataset are: \\n {raw_data.head()} \\n\")\n",
    "\n",
    "# Transformation:\n",
    "# Creating a new column 'total_price' by multiplying 'quantity' by 'unit_price'\n",
    "raw_data['total_price'] = raw_data['quantity'] * raw_data['unit_price']\n",
    "\n",
    "# After Transformation:\n",
    "# Displaying the first 5 observations along with their columns in the dataset\n",
    "print(f\"The first 5 observations in the dataset after adding a new column are: \\n {raw_data.head()} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d8df2",
   "metadata": {},
   "source": [
    "Explanation:\n",
    " \n",
    "    Creating a new column 'total_price' by multiplying 'quantity' by 'unit_price', so as to obtain the total sales which could be informative when carrying out further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current data types are: \n",
      " order_id           int64\n",
      "customer_name     object\n",
      "product           object\n",
      "quantity         float64\n",
      "unit_price       float64\n",
      "order_date        object\n",
      "region            object\n",
      "total_price      float64\n",
      "dtype: object \n",
      "\n",
      "The data types after tranformation are: \n",
      " order_id                  int64\n",
      "customer_name            object\n",
      "product                  object\n",
      "quantity                float64\n",
      "unit_price              float64\n",
      "order_date       datetime64[ns]\n",
      "region                   object\n",
      "total_price             float64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Structurally changing 'raw_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "# Displaying data types\n",
    "print(f\"The current data types are: \\n {raw_data.dtypes} \\n\")\n",
    "\n",
    "# Transformation\n",
    "# Converting 'order_date' to a datetime format\n",
    "raw_data['order_date'] = pd.to_datetime(raw_data['order_date'])\n",
    "\n",
    "# After transformation\n",
    "print(f\"The data types after tranformation are: \\n {raw_data.dtypes} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5472b7",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "    Converting 'order_date' column from 'object' to a datetime format for easier date manipulation and calculations, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e688ade4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns in the dataset are: \n",
      " Index(['order_id', 'customer_name', 'product', 'quantity', 'unit_price',\n",
      "       'order_date', 'region', 'total_price'],\n",
      "      dtype='object') \n",
      " \n",
      "The columns in the dataset after transformation are: \n",
      " Index(['order_id', 'product', 'quantity', 'unit_price', 'order_date', 'region',\n",
      "       'total_price'],\n",
      "      dtype='object') \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Filtering 'raw_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "# Displaying all the columns in the data set\n",
    "print(f\"The columns in the dataset are: \\n {raw_data.columns} \\n \")\n",
    "\n",
    "# Transformation\n",
    "# Dropping irrelevant columns\n",
    "raw_data.drop(columns=['customer_name'], inplace=True)\n",
    "\n",
    "# After transformation\n",
    "# Displaying all the columns in the data set\n",
    "print(f\"The columns in the dataset after transformation are: \\n {raw_data.columns} \\n \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0b2b09",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "    Dropping 'customer_name' column in the dataset as it won't help much in analysis. Futhermore,to reduce the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b3b9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving transformed 'raw_data.csv'\n",
    "raw_data.to_csv('2_transformed/transformed_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f49f3",
   "metadata": {},
   "source": [
    "## incremental_data.csv\n",
    "\n",
    "Apply at least 4 meaningful transformations:\n",
    "\n",
    "- Cleaning: Handle missing values, remove duplicates\n",
    "\n",
    "- Enrichment: Add 'total_price' = 'quantity' * 'unit_price'\n",
    "\n",
    "- Structural: Convert dates, change data types\n",
    "\n",
    "- Filtering: Drop irrelevant columns or rows\n",
    "\n",
    "- Categorization: Create age bins, customer tiers\n",
    "\n",
    "Save the transformed files to 'transformed/' folder\n",
    "\n",
    "NB: \n",
    "\n",
    "- Show before and after for each transformation.\n",
    "\n",
    "- Explain what and why you are transforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f400e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Loading 'incremental_data.csv'\n",
    "incremental_data = pd.read_csv(\"incremental_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41a89323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of missing values before transformation are: \n",
      " order_id         0\n",
      "customer_name    6\n",
      "product          0\n",
      "quantity         4\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           2\n",
      "dtype: int64 \n",
      "\n",
      "The number of duplicate rows before transformation include: \n",
      " 0 \n",
      "\n",
      "The number of missing values after transformation are: \n",
      " order_id         0\n",
      "customer_name    0\n",
      "product          0\n",
      "quantity         0\n",
      "unit_price       0\n",
      "order_date       0\n",
      "region           0\n",
      "dtype: int64 \n",
      "\n",
      "The number of duplicate rows after transformation include: \n",
      " 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cleaning 'incremental_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "missing_values_incremental = incremental_data.isnull().sum()\n",
    "print(f\"The number of missing values before transformation are: \\n {missing_values_incremental} \\n\")\n",
    "\n",
    "duplicates_incremental = incremental_data.duplicated().sum()\n",
    "print(f\"The number of duplicate rows before transformation include: \\n {duplicates_incremental} \\n\")\n",
    "\n",
    "# Transformation:\n",
    "# Fill missing values\n",
    "for col in incremental_data.columns:\n",
    "    if incremental_data[col].dtype in ['int64', 'float64']:\n",
    "        incremental_data[col] = incremental_data[col].fillna(incremental_data[col].mean())\n",
    "    else:\n",
    "        incremental_data[col] = incremental_data[col].fillna(incremental_data[col].mode()[0])\n",
    "# Remove duplicates\n",
    "incremental_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# After transformation\n",
    "missing_values_after_1 = incremental_data.isnull().sum()\n",
    "print(f\"The number of missing values after transformation are: \\n {missing_values_after_1} \\n\")\n",
    "\n",
    "duplicates_after_1 = incremental_data.duplicated().sum()\n",
    "print(f\"The number of duplicate rows after transformation include: \\n {duplicates_after_1} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27588c3e",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "    Handling missing values is essential to avoid errors during analysis. Therefore, filled numerical columns with its corresponding mean and descriptive columns with its corresponding mode.\n",
    "\n",
    "    To ensure data integrity, duplicate rows are removed (but in this case, there are none thus no row is removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2429d463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 observations in the dataset are: \n",
      "    order_id customer_name product  quantity  unit_price  order_date   region\n",
      "0       101         Alice  Laptop       1.5       900.0  2024-05-09  Central\n",
      "1       102         Heidi  Laptop       1.0       300.0  2024-05-07  Central\n",
      "2       103         Heidi  Laptop       1.0       600.0  2024-05-04  Central\n",
      "3       104         Heidi  Tablet       1.5       300.0  2024-05-26  Central\n",
      "4       105         Heidi  Tablet       2.0       600.0  2024-05-21    North \n",
      "\n",
      "The first 5 observations in the dataset after adding a new column are: \n",
      "    order_id customer_name product  quantity  unit_price  order_date   region  \\\n",
      "0       101         Alice  Laptop       1.5       900.0  2024-05-09  Central   \n",
      "1       102         Heidi  Laptop       1.0       300.0  2024-05-07  Central   \n",
      "2       103         Heidi  Laptop       1.0       600.0  2024-05-04  Central   \n",
      "3       104         Heidi  Tablet       1.5       300.0  2024-05-26  Central   \n",
      "4       105         Heidi  Tablet       2.0       600.0  2024-05-21    North   \n",
      "\n",
      "   total_price  \n",
      "0       1350.0  \n",
      "1        300.0  \n",
      "2        600.0  \n",
      "3        450.0  \n",
      "4       1200.0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enriching 'incremental_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "# Displaying the first 5 observations along with their columns in the dataset\n",
    "print(f\"The first 5 observations in the dataset are: \\n {incremental_data.head()} \\n\")\n",
    "\n",
    "# Transformation:\n",
    "# Creating a new column 'total_price' by multiplying 'quantity' by 'unit_price'\n",
    "incremental_data['total_price'] = incremental_data['quantity'] * incremental_data['unit_price']\n",
    "\n",
    "# After Transformation:\n",
    "# Displaying the first 5 observations along with their columns in the dataset\n",
    "print(f\"The first 5 observations in the dataset after adding a new column are: \\n {incremental_data.head()} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7bac14",
   "metadata": {},
   "source": [
    "Explanation:\n",
    " \n",
    "    Creating a new column 'total_price' by multiplying 'quantity' by 'unit_price', so as to obtain the total sales which could be informative when carrying out further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3122323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current data types are: \n",
      " order_id           int64\n",
      "customer_name     object\n",
      "product           object\n",
      "quantity         float64\n",
      "unit_price       float64\n",
      "order_date        object\n",
      "region            object\n",
      "total_price      float64\n",
      "dtype: object \n",
      "\n",
      "The data types after tranformation are: \n",
      " order_id                  int64\n",
      "customer_name            object\n",
      "product                  object\n",
      "quantity                float64\n",
      "unit_price              float64\n",
      "order_date       datetime64[ns]\n",
      "region                   object\n",
      "total_price             float64\n",
      "dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Structurally changing 'incremental_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "# Displaying data types\n",
    "print(f\"The current data types are: \\n {incremental_data.dtypes} \\n\")\n",
    "\n",
    "# Transformation\n",
    "# Converting 'order_date' to a datetime format\n",
    "incremental_data['order_date'] = pd.to_datetime(incremental_data['order_date'])\n",
    "\n",
    "# After transformation\n",
    "print(f\"The data types after tranformation are: \\n {incremental_data.dtypes} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10de6275",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "    Converting 'order_date' column from 'object' to a datetime format for easier date manipulation and calculations, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3e6a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns in the dataset are: \n",
      " Index(['order_id', 'customer_name', 'product', 'quantity', 'unit_price',\n",
      "       'order_date', 'region', 'total_price'],\n",
      "      dtype='object') \n",
      " \n",
      "The columns in the dataset after transformation are: \n",
      " Index(['order_id', 'product', 'quantity', 'unit_price', 'order_date', 'region',\n",
      "       'total_price'],\n",
      "      dtype='object') \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Filtering 'incremental_data.csv'\n",
    "\n",
    "# Before transformation:\n",
    "# Displaying all the columns in the data set\n",
    "print(f\"The columns in the dataset are: \\n {incremental_data.columns} \\n \")\n",
    "\n",
    "# Transformation\n",
    "# Dropping irrelevant columns\n",
    "incremental_data.drop(columns=['customer_name'], inplace=True)\n",
    "\n",
    "# After transformation\n",
    "# Displaying all the columns in the data set\n",
    "print(f\"The columns in the dataset after transformation are: \\n {incremental_data.columns} \\n \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e907c75",
   "metadata": {},
   "source": [
    "Explanation: \n",
    "\n",
    "    Dropping 'customer_name' column in the dataset as it won't help much in analysis. Futhermore,to reduce the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3228c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving transformed 'incremental_data.csv'\n",
    "incremental_data.to_csv('2_transformed/transformed_incremental.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
